\documentclass[]{article}

\usepackage{nameref}
\usepackage[a4paper,top=3cm,bottom=4cm,left=3.5cm,right=3.5cm]{geometry}
\usepackage[font=footnotesize,labelfont={sf,bf}]{caption}
\usepackage{graphicx}
\usepackage{float}
\usepackage{lmodern}
\usepackage{diagbox}
\usepackage{booktabs}
\usepackage{siunitx}

\graphicspath{ {./assets/latexImages/} }

\def\code#1{\texttt{#1}}

\title{SPM Project: BSP}
\author{Lorenzo Bellomo, 531423}
\date{AA 2018/2019}

\begin{document}

\maketitle

\section{Introduction}

In this report the \emph{Bulk Synchronous Pattern} (BSP) will be analysed both from a theoretical viewpoint and from a practical one. \\
The outline of the report will be the following:
\begin{itemize}
	\item Section \ref{sec:parDesign} (\nameref{sec:parDesign}).
	\item Section \ref{sec:perfModel} (\nameref{sec:perfModel}).
	\item Section \ref{sec:implDetails} (\nameref{sec:implDetails}).
	\item Section \ref{sec:eval} (\nameref{sec:eval}).
	\item Section \ref{sec:conclusion} (\nameref{sec:conclusion}).
\end{itemize}

\section{Parallel Architecture Design}
\label{sec:parDesign}

BSP is by nature a parallel bridging model. The main idea is that the process is divided in three phases (as shown in figure \ref{fig:BSP}):
\begin{itemize}
	\item \emph{Local computation}: The processors act independently and compute their task on a different partition of the input data.
	\item \emph{Communication}: In this phase processors are allowed to send data to the other ones. It is important to notice that phase 1 and 2 (super step and communication) may overlap in case of uneven input workload.
	\item \emph{Synchronization}: In this phase all the processors synchronize and wait that the communication phase is over for each worker (\emph{barrier}).
\end{itemize}
This whole process made of 3 phases composes a \emph{super step}.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.45\linewidth]{bsp}
	\caption{BSP structure}
	\label{fig:BSP}
\end{figure}

\section{Performance Modelling}
\label{sec:perfModel}

In order to theoretically model the performances of a BSP algorithm some values are going to be defined:
\begin{itemize}
	\item $\mathit{nw}$ is the number of workers (BSP processors).
	\item $k$ is the number of super steps
	\item $w_i$ is the time spent by the \emph{i-th} worker in the compute phase.
	\item $m_i$ is the number of maximum messages receiver by the \emph{i-th} worker.
	\item $c$ is the cost of sending or receiving one message.
	\item $B$ is the cost of the synchronization step (\emph{barrier}).
	\item $I$ and $F$ are relatively the initialization and finalization cost. Their value is application specific.
\end{itemize}
The cost of a super step ($\mathit{SS}$) can be approximated (upper bounded) as follows:
$$ \mathit{SS}_j = \max_{i=1}^{\mathit{nw}} w_i + \max_{i=1}^{\mathit{nw}} c m_i + B $$
Which eventually gives:
$$ \mathit{tot\_cost} = I + \sum_{j=1}^{k} \mathit{SS}_j + F $$
\subsection{Opportunities for parallelism}
According to the model provided, the opportunities for parallelization reside in the \emph{super step cost}, which ideally should decrease linearly by increasing the number of parallel activities. In particular, it is safe to assume that $w_i = \Theta(n/\mathit{nw}) \, \forall i$, while instead both the communication cost and the barrier cost are pure overhead, which grows with $\mathit{nw}$. \\
In this particular problem, the parallel design is already provided, but the goal of the implementation is to minimize the overheads, with particular focus on the \emph{communication} one, which can be assumed to be the most costly. \\

For what regards the user provided business logic code, which regards both the computation phase and the communication one, the scalability of the provided \emph{BSP} depends on the goodness of the business logic code.

\section{Implementation Structure and Details}
\label{sec:implDetails}

All the source code files are under directory \emph{src} and are provided under the form of header only files. \\The files provided are:
\begin{itemize}
	\item \code{sorter.cpp}: it contains the main method. 
	\item \code{sorterLogic.hpp}: it contains the business logic code for the custom \emph{BSP} execution with standard \emph{POSIX} threads.
	\item \code{posixBSP.hpp}: it contains the implementation (with \emph{POSIX} threads) of the BSP pattern.
	\item \code{logicBSP.hpp}: it contains the interface that hosts the business logic code abstraction. Every application should subclass the one provided in this file to provide the business logic code. More in section \ref{sec:business}.
	\item \code{barrier.hpp}: it contains an implementation of a reusable (context aware) barrier, implemented with a mutex and a condition variable.
	\item \code{safeQueue.hpp}: it contains the queue implementation used. Its discussion will be delayed to section \ref{sec:queue}.
	\item \code{queueMatrix.hpp}: It contains a class to handle a matrix of queues. Its use will be to give to every worker a queue \emph{for each} super step. The matrix dimension will be $matrix[\#\mathit{ss}][\mathit{nw}]$.
	\item \code{utimer.hpp}
	\item \code{makefile}
	\item \code{benchmark}: This folder will be analysed in section \ref{sec:benchFold}.
\end{itemize}

\subsection{Communications}
\label{sec:queue}
The queue implementation is a modification of the one provided during classes. The main difference is that writes to the queue are synchronized, while reads are not. \\ This is made possible by the fact that reads are always performed after a barrier, which makes the synchronization implicit. Writes have to be executed in mutual exclusion because multiple producers may potentially write together. In order to reduce the synchronization overhead, it is suggested to use the method \code{push\_multiple(iterator, iterator)}, in order to lock once the queue and then release it immediately.

\subsection{Threads}
The code of the threads is a private function (\code{worker}) in file \code{posixBSP.hpp}. \\
As explained, one thread executes the code of one worker (which may comprise more super steps), so in total only $\mathit{nw}$ threads are spawned by the runtime.


\subsection{Business Logic Code}
\label{sec:business}
In order to write code that can be fed to the provided BSP implementation, one has to subclass \code{logicBSP}. This is an interface that models a generic worker (see \code{sorterLogic.hpp} for an example). \\
One has to provide the code of the worker's \emph{super steps} (every worker has its own local state) and it must provide a switcher function that maps every function to a super step number. \\
The code of a generic super step has to be a function with this signature (except for the function name, which might vary): 
\begin{figure}[H]
	\centering
	\begin{minipage}{0.9\textwidth}		
		\code{void ss(logicBSP::ss\_queue, size\_t, std::vector<logicBSP::ss\_queue>)}
	\end{minipage}
\end{figure}
Where \code{logicBSP::ss\_queue} is just an alias for a pointer to a \code{safe\_queue<T>}. The runtime will give the handle to the workers' \emph{input queue} and the collection of \emph{output\_queues}, indexed exactly like the workers (where \code{output\_queues[i]} is the queue belonging to worker \code{i}). \\
This way, every worker keeps its own local state, which survives every super step call.

\section{Experimental Evaluation}
\label{sec:eval}
Benchmark data were collected with the provided scripts in the \code{benchmark} folder (see section \ref{sec:benchFold}), while the data were gathered and displayed in section \ref{sec:plots}. \\
The test have been made on the \emph{Xeon Phi} and the results shown refer exclusively to data collected on that machine. \\
The project was compiled with \code{g++} version \code{7.4.0} provided on the machine, and with the options provided in the \code{makefile}. \\
The program can be compiled with different preprocessor \code{define} in order to change a bit the behaviour of the programs. The possibilities are listed below (and are used in the \code{makefile} for various rules):
\begin{itemize}
	\item \code{DEBUG}: (used in rule \code{make debug}) it activates the flag \code{-g} useful for debugging with \code{gdb}, and it checks that the output vector is equal to the one computed using \code{std::sort}.
	\item \code{BENCHMARK}: (used in rule \code{make benchmark}) it skips computing the \code{std::sort}, and only sorts the input array via the \emph{Tiskin} algorithm.
	\item \code{TSEQ}: (used in rule \code{make tseq}) this signals that the user wants to collect some partial execution data (like the synchronization time, the super step time and so on). In this case the final time is higher due to the collection of partial times overhead.
\end{itemize}

\subsection{Benchmark Folder}
\label{sec:benchFold}
This folder is organized as follows:
\begin{itemize}
	\item \code{benchmark.sh}: This bash script automates the benchmarking process. It starts the program with different parallelism degrees and different input vector sizes. It executes every combination of $n$ (size of input vector) and $\mathit{nw}$ 3 times in order to then compute an average of each time. The analysis of its output is delayed to section \ref{sec:benchmark}.
	\item \code{gprof-helper.c}: This file is needed in order to allow \code{gprof} profiling for multithreaded applications. It provides wrappers for the \code{pthread} creation.
	\item \code{profiler.sh}: This bash script automates the profiling process. At the end of the script execution, it dumps the profiling output in a file, by starting the program with various parallelism degrees. The analysis of its output is delayed to section \ref{sec:profile}.
	\item \code{tseq.sh}: This bash script collects some times from the program execution. In particular, it collects, for each worker, the \emph{super step} time, the \emph{barrier} synchronization delay and something similar. Also in this case, times are collected with various parallelism degrees. The analysis of its output is delayed to section \ref{sec:tseq}.
\end{itemize}
All the cited scripts collect data and dump them in various files, that go in the folder \code{benchmark/data/}, which gets generated by those scripts.

\subsection{Collection of Partial Times}
\label{sec:tseq}
In table \ref{tab:tseq} some partial times collected are shown. All the times are expressed in microseconds and are the result of an average between multiple runs.\\
The labels shown are described below:
\begin{itemize}
	\item \emph{ss computation}: it is an average of the time spent by a generic super step (average of the three) in computation phase.
	\item \emph{ss communication}: same thing but related to communications.
	\item \emph{barrier sync}: time spent by a generic super step waiting for all the workers to end their local computation and their communication. This is the value with the highest \emph{variance}.
\end{itemize}
\begin{table}[H]
	\centering
	\begin{tabular}{l|*{9}r}
		\toprule
		\diagbox{phase}{$\mathit{nw}$} 
		& 1 & 2 & 4 & 8 & 16 & 32 & 64 & 128 & 256 \\
		\midrule
		ss computation \\
		ss communication \\
		barrier sync \\
		\bottomrule
	\end{tabular}%
	\caption{Collections of partial times (in \SI{}{\micro \second})}
	\label{tab:tseq}%
\end{table}%

\subsection{Benchmark}
\label{sec:benchmark}
The raw data collected through the \code{benchmark.sh} script are shown in table \ref{tab:benchmark}. The time is shown in milliseconds, and it is the result of an average of multiple runs.
\begin{table}[H]
	\centering
	\begin{tabular}{l|*{10}r}
		\toprule
		\diagbox{$n$}{$\mathit{nw}$} 
		& 1 & 2 & 4 & 8 & 16 & 32 & 64 & 128 & 256 & std::sort \\
		\midrule
		$2^{20}$ & 294 & 306 & 146 & 86 & 64 & 66 & 113 & 336 & 2\,684 & 186 \\
		$2^{21}$ & 595 & 645 & 258 & 161 & 112 & 96 & 144 & 343  & 2\,675 & 392 \\
		$2^{22}$ & 1\,219 & 1\,417 & 530 & 303 & 203 & 152 & 200  & 381 & 2\,643 & 823 \\
		$2^{23}$ & 2\,494 & 2\,787 & 1\,060 & 586 & 362 & 280 & 295 & 722 & 2\,211  & 1\,705 \\
		$2^{24}$ & 5\,175 & 5\,781 & 2\,431 & 1\,186 & 712 & 454 & 429 & 923 & 1\,539 & 3\,577 \\
		$2^{25}$ & 10\,751 & 12\,309 & 4\,867 & 2\,575 & 1\,393 & 851 & 770 & 1\,198 & 1\,797 & 7\,460 \\
		$2^{26}$ & 22\,390 & 25\,220 & 11\,353 & 5\,191& 3\,245 & 1\,665 & 1\,224 & 1\,543 & 4\,016 & 15\,579 \\
		$2^{27}$ & 48\,066 & 56\,732 & 23\,548 & 12\,145 & 6\,788 & 4\,928 & 2\,191 & 2\,132 & 5\,041 & 30\,804 \\
		
		\bottomrule
	\end{tabular}%
	\caption{Time collected and averaged (in \SI{}{\milli \second})}
	\label{tab:benchmark}
\end{table}%
Some plots related to those data are shown in section \ref{sec:plots}.


\subsection{Profiling}
\label{sec:profile}
According to \code{gprof}, the most time consuming operations are 

\subsection{Plots}
\label{sec:plots}
In this section some plots related to data generated with the script \code{benchmark.sh} are shown.

\section{Conclusions}
\label{sec:conclusion}

\end{document}
